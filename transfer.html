<!DOCTYPE html>
<html>
  <head>
    <meta charset='utf-8'>
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    <link href='https://fonts.googleapis.com/css?family=Architects+Daughter' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" type="text/css" href="stylesheets/stylesheet.css" media="screen">
    <link rel="stylesheet" type="text/css" href="stylesheets/github-light.css" media="screen">
    <link rel="stylesheet" type="text/css" href="stylesheets/print.css" media="print">

    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->

    <title>Small Steps of Main to BIG by rbheemana</title>
  </head>

  <body>
    <header>
      <div class="inner">
        <h1>Small Steps of Main to BIG</h1>
        <h2>Serde for Cobol Layout to Hive table</h2>
        <a href="https://github.com/rbheemana/Cobol-to-Hive" class="button"><small>View project on</small> GitHub</a>
      </div>
    </header>

    <div id="content-wrapper">
      <div class="inner clearfix">
        <section id="main-content">
          <a href="http://rbheemana.github.io/Cobol-to-Hive/" style="float: left;"> 01 Introduction << </a>
          <a href="http://rbheemana.github.io/Cobol-to-Hive/serde.html" style="float: right;"> 03 Cobol to Hive Serde >> </a>
          
          <h3>
<a id="transfer-of-mainframe-file-to-hdfs" class="anchor" href="#transfer-of-mainframe-file-to-hdfs" aria-hidden="true"><span class="octicon octicon-link"></span></a>Transfer of mainframe file to HDFS</h3>

<p>Generally, when we need a file from other systems to hadoop, we get the data to edge using FTP/SFTP/CURL etc protocols.
But when you are FTPing the data from mainframe system (Ofcourse mainframe ftp port should be opened) you need to extra careful to download the data the binary format. This is required since the mainframe uses EBCDIC encoding. One could argue to convert the file to ASCII while FTPing the data. That would work perfectly fine if the file that you are downloading has no usage of any computational fields. Examples of such are copybooks, code, plain text, etc. Problem arises when the data consists of computational fields, one should convert data to ASCII excluding these fields. This action become complicated as the position of the such fields can only be determined by its layout.</p>

<p>For now lets import the mainframe data without converting to ASCII, that is in EBCIDIC format. We can achieve this by copying the data to edgenode whatever protocol is common between two systems and then using hdfs dfs -put command to transfer to HDFS.</p>

<p>Personally, I have written simple java program to connect to mainframe system using FTP Client API and bring the data directly to the HDFS.</p>

<h3>
<a id="usage-of-my-program-to-ftp-the-file" class="anchor" href="#usage-of-my-program-to-ftp-the-file" aria-hidden="true"><span class="octicon octicon-link"></span></a>Usage of my program to FTP the file</h3>

<p>'''''
export 
export
export
export
jar CobolSerde.jar  
'''''</p>

<h3>
<a id="code-logic" class="anchor" href="#code-logic" aria-hidden="true"><span class="octicon octicon-link"></span></a>Code Logic</h3>
        </section>

        <aside id="sidebar">
          <a href="https://github.com/rbheemana/Cobol-to-Hive/zipball/master" class="button">
            <small>Download</small>
            .zip file
          </a>
          <a href="https://github.com/rbheemana/Cobol-to-Hive/tarball/master" class="button">
            <small>Download</small>
            .tar.gz file
          </a>

          <p class="repo-owner"><a href="https://github.com/rbheemana/Cobol-to-Hive"></a> is maintained by <a href="https://github.com/rbheemana">rbheemana</a>.</p>

          <p>This page was generated by <a href="https://pages.github.com">GitHub Pages</a> using the Architect theme by <a href="https://twitter.com/jasonlong">Jason Long</a>.</p>
        </aside>
      </div>
    </div>

  
  </body>
</html>
